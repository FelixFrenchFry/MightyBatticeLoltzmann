#!/bin/bash -x
#SBATCH --job-name=cuda_mpi_04_test_BIGGER
#SBATCH --partition=gpu_a100_il
#SBATCH --nodes=6
#SBATCH --ntasks-per-node=4
#SBATCH --gres=gpu:4
#SBATCH --cpus-per-task=8
#SBATCH --time=00:13:00
#SBATCH --mem=256gb
#SBATCH --output=job_%j.out
#SBATCH --error=job_%j.err

module load toolkit/nvidia-hpc-sdk/25.1

# propagate toolchain vars
export CC=gcc
export CXX=g++
export CUDA_PATH=/software/bwhpc/common/toolkit/nvidia_hpc_sdk/25.1/Linux_x86_64/25.1/cuda

# build it
cd $HOME/MightyBatticeLoltzmann
meson setup buildDir --wipe --buildtype=release
ninja -C buildDir implementations/cuda_mpi/cuda_mpi_04

# launch it with different configurations (basic)
#mpirun --bind-to none --map-by ppr:4:node -np 32 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_03.txt

mpirun --bind-to none --map-by ppr:4:node -np 24 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_03.txt

mpirun --bind-to none --map-by ppr:4:node -np 20 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_03.txt

mpirun --bind-to none --map-by ppr:3:node -np 16 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_03.txt

mpirun --bind-to none --map-by ppr:2:node -np 12 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_03.txt

mpirun --bind-to none --map-by ppr:2:node -np 8 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_03.txt

mpirun --bind-to none --map-by ppr:1:node -np 4 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_03.txt

# launch it with different configurations (special)
#mpirun --bind-to none --map-by ppr:4:node -np 32 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_02.txt

mpirun --bind-to none --map-by ppr:4:node -np 24 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_02.txt

mpirun --bind-to none --map-by ppr:4:node -np 20 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_02.txt
