#!/bin/bash -x
#SBATCH --job-name=cuda_mpi_04_test_OBERSUB_C
#SBATCH --partition=gpu_h100
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=4
#SBATCH --gres=gpu:4
#SBATCH --cpus-per-task=8
#SBATCH --time=00:12:00
#SBATCH --mem=128gb
#SBATCH --output=job_%j.out
#SBATCH --error=job_%j.err

module load toolkit/nvidia-hpc-sdk/25.1

# propagate toolchain vars
export CC=gcc
export CXX=g++
export CUDA_PATH=/software/bwhpc/common/toolkit/nvidia_hpc_sdk/25.1/Linux_x86_64/25.1/cuda

# build it
cd $HOME/MightyBatticeLoltzmann
meson setup buildDir --wipe --buildtype=release
ninja -C buildDir implementations/cuda_mpi/cuda_mpi_04

# launch it with different configurations (oversubscribed)
mpirun --bind-to none --map-by ppr:4:node -np 8 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt

mpirun --bind-to none --map-by ppr:8:node -np 16 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt

mpirun --bind-to none --map-by ppr:12:node -np 24 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt

mpirun --bind-to none --map-by ppr:16:node -np 32 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt

mpirun --bind-to none --map-by ppr:20:node -np 40 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt

mpirun --bind-to none --map-by ppr:24:node -np 48 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt

mpirun --bind-to none --map-by ppr:28:node -np 56 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt

mpirun --bind-to none --map-by ppr:32:node -np 64 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt

mpirun --bind-to none --map-by ppr:36:node -np 72 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt

mpirun --bind-to none --map-by ppr:40:node -np 80 ./buildDir/implementations/cuda_mpi/cuda_mpi_04 input_04.txt
